{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WineRatings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAEDKGicTKEZNvuRtdLbyp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fimbrez/PersonalProjects/blob/main/WineRatings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC7qQx9dZMO"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "497HCA66eATK"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# read csv file into pyspark dataframe\n",
        "infile = 'winemag-data-130k-v2.csv'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Winemag Wine\") \\\n",
        "    .getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLmN0hcveI1q"
      },
      "source": [
        "df = spark.read.csv(infile, inferSchema=True, header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiQBpKyoeLNZ"
      },
      "source": [
        "type(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b8cEdf6eNl-"
      },
      "source": [
        "#showing df schema; see all the variables we will be using\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBWcHxrFePel"
      },
      "source": [
        "#Look at data\n",
        "df.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt92VTcVfFGD"
      },
      "source": [
        "# Linear Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54TnV4GfLZ5"
      },
      "source": [
        "### Price as a predictor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q0TQXYLeRkO"
      },
      "source": [
        "#subsetting the data to prepare it for linear regression\n",
        "vars_to_keep = [\"points\",\"price\"]\n",
        "\n",
        "# subset the dataframe on these predictors\n",
        "df2 = df.select(vars_to_keep)\n",
        "df2.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCKuuHbSeTeq"
      },
      "source": [
        "#importing libararies we will be using\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml.feature import VectorAssembler \n",
        "from pyspark.mllib.linalg import Vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po9SkcgleVnm"
      },
      "source": [
        "#Renaming the response variables\n",
        "df2 = df2.withColumnRenamed(\"points\",\"Ratings\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9TctaideXZh"
      },
      "source": [
        "df2.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YicpYp6UeY5i"
      },
      "source": [
        "#Removing null values\n",
        "df2 = df2.filter(df2.price.isNotNull())\n",
        "df2 = df2.filter(df2.Ratings.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIXQOJhTeavl"
      },
      "source": [
        "#Looking at df2 now\n",
        "df2.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_wGaV1Hecq2"
      },
      "source": [
        "#Typecasting the variables to integers\n",
        "from pyspark.sql.types import IntegerType\n",
        "df2 = df2.withColumn(\"Ratings\", df2[\"Ratings\"].cast(\"float\"))\n",
        "df2 = df2.withColumn(\"price\", df2[\"price\"].cast(\"float\")) #needs to be of type array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtDR34KDeekP"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=[\"price\"], outputCol=\"features\") \n",
        "df2 = assembler.transform(df2.na.drop())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrb_K88BegSP"
      },
      "source": [
        "#dropping the price column\n",
        "df2 = df2.drop(\"price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjGrEz25eidd"
      },
      "source": [
        "df2.show(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypa76fLEekHh"
      },
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0XQQfaIep46"
      },
      "source": [
        "# Split data approximately into training (60%) and test (40%)\n",
        "seed = 314\n",
        "train_test = [0.6, 0.4]\n",
        "train_data, test_data = df2.randomSplit(train_test, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEEa5tMnerns"
      },
      "source": [
        "train_data.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d73TmbWfet5z"
      },
      "source": [
        "#checking count of training and test to match up with total\n",
        "(train_data.count(), test_data.count(), df2.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRTV_83mev6J"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression # note this is from the ML package\n",
        "\n",
        "maxIter=10\n",
        "regParam=0.3\n",
        "elasticNetParam=0.8\n",
        "\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol = 'Ratings', maxIter = maxIter, \n",
        "                      regParam = regParam, elasticNetParam = elasticNetParam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY8PG5q_exhG"
      },
      "source": [
        "model1 = lr.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7D_tuDCezEI"
      },
      "source": [
        "lrPred = model1.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMUCfYUre0gf"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol = \"Ratings\", predictionCol = \"prediction\",\n",
        "                          metricName = \"rmse\")\n",
        "mse = eval.evaluate(lrPred, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIeJdDG1e5J8"
      },
      "source": [
        "### Variety, Winery, and Country as predictors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JID9gEVse2G9"
      },
      "source": [
        "#subsetting the data to prepare it for linear regression\n",
        "vars_to_keep = [\"variety\",\"winery\",\"country\",\"points\"]\n",
        "\n",
        "# subset the dataframe on these predictors\n",
        "df3 = df.select(vars_to_keep)\n",
        "df3.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SegddSmYfTxW"
      },
      "source": [
        "#### Encoding the string-valued data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtGpLqVofQF3"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").setHandleInvalid(\"skip\").fit(df3) for column in list(set(df3.columns)-set(['points'])) ]\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df3 = pipeline.fit(df3).transform(df3)\n",
        "\n",
        "df3.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nNuceV_fXk9"
      },
      "source": [
        "#Renaming the response variables\n",
        "df3 = df3.withColumnRenamed(\"points\",\"Ratings\")\n",
        "df3 = df3.withColumn(\"Ratings\", df3[\"Ratings\"].cast(\"float\"))\n",
        "df3 = df3.withColumn(\"variety_index\", df3[\"variety_index\"].cast(\"float\"))\n",
        "df3 = df3.withColumn(\"winery_index\", df3[\"winery_index\"].cast(\"float\"))\n",
        "df3 = df3.withColumn(\"country_index\", df3[\"country_index\"].cast(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUjsUSGXfbRt"
      },
      "source": [
        "# dropping the string-valued columns\n",
        "df3 = df3.select([\"Ratings\",\"variety_index\",\"winery_index\",\"country_index\"])\n",
        "df3 = df3.filter(df3.variety_index.isNotNull())\n",
        "df3 = df3.filter(df3.Ratings.isNotNull())\n",
        "df3 = df3.filter(df3.country_index.isNotNull())\n",
        "df3 = df3.filter(df3.winery_index.isNotNull())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56elQTSffdFF"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=[\"variety_index\",\"winery_index\",\"country_index\"], outputCol=\"features\") \n",
        "df3 = assembler.transform(df3.na.drop())\n",
        "df3.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsfCDyYjfeyV"
      },
      "source": [
        "df3 = df3.select(\"Ratings\",\"features\")\n",
        "df3.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp0WRIRMfgc9"
      },
      "source": [
        "# Feature scaling\n",
        "\n",
        "# Initialize the `standardScaler`\n",
        "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", \n",
        "                                withStd=True, withMean=False)\n",
        "\n",
        "# Fit the DataFrame to the scaler; this computes the mean, standard deviation of each feature\n",
        "scaler = standardScaler.fit(df3)\n",
        "\n",
        "# Transform the data in `df2` with the scaler\n",
        "scaled_df = scaler.transform(df3)\n",
        "scaled_df.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUIAzXpDfiKl"
      },
      "source": [
        "# Split data approximately into training (60%) and test (40%)\n",
        "seed = 314\n",
        "train_test = [0.6, 0.4]\n",
        "train_data, test_data = df3.randomSplit(train_test, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-0Rc8xffjyy"
      },
      "source": [
        "model2 = lr.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQFejiRUflh4"
      },
      "source": [
        "lrPred2 = model2.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pixBB9AAfnnz"
      },
      "source": [
        "mse = eval.evaluate(lrPred2, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MDtW-ysfrsJ"
      },
      "source": [
        "### Price, Variety, Winery, and Country as predictors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfYQ65Bcfs9j"
      },
      "source": [
        "vars_to_keep = [\"variety\",\"winery\",\"country\",\"points\",\"price\"]\n",
        "\n",
        "# subset the dataframe on these predictors\n",
        "df4 = df.select(vars_to_keep)\n",
        "df4.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-8wdAzfuqk"
      },
      "source": [
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").setHandleInvalid(\"skip\").fit(df4) for column in list(set(df4.columns)-set(['points','price'])) ]\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df4 = pipeline.fit(df4).transform(df4)\n",
        "\n",
        "df4.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5YSsVXqfwaG"
      },
      "source": [
        "df4 = df4.withColumnRenamed(\"points\",\"Ratings\")\n",
        "df4 = df4.withColumn(\"Ratings\", df4[\"Ratings\"].cast(\"float\"))\n",
        "df4 = df4.withColumn(\"variety_index\", df4[\"variety_index\"].cast(\"float\"))\n",
        "df4 = df4.withColumn(\"winery_index\", df4[\"winery_index\"].cast(\"float\"))\n",
        "df4 = df4.withColumn(\"country_index\", df4[\"country_index\"].cast(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wemRh7jHfyFw"
      },
      "source": [
        "df4 = df4.select([\"Ratings\",\"variety_index\",\"winery_index\",\"country_index\",\"price\"])\n",
        "df4 = df4.filter(df4.variety_index.isNotNull())\n",
        "df4 = df4.filter(df4.Ratings.isNotNull())\n",
        "df4 = df4.filter(df4.country_index.isNotNull())\n",
        "df4 = df4.filter(df4.winery_index.isNotNull())\n",
        "df4 = df4.filter(df4.price.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QdrhvzDf0Pp"
      },
      "source": [
        "df4 = df4.withColumn(\"price\", df4[\"price\"].cast(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbhVtPB8f2Cc"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=[\"variety_index\",\"winery_index\",\"country_index\",\"price\"], outputCol=\"features\") \n",
        "df4 = assembler.transform(df4.na.drop())\n",
        "df4.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhI82jV_f3pq"
      },
      "source": [
        "df4 = df4.select(\"Ratings\",\"features\")\n",
        "df4.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyPnAsz6f5W_"
      },
      "source": [
        "# Initialize the `standardScaler`\n",
        "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", \n",
        "                                withStd=True, withMean=False)\n",
        "\n",
        "# Fit the DataFrame to the scaler; this computes the mean, standard deviation of each feature\n",
        "scaler = standardScaler.fit(df4)\n",
        "\n",
        "# Transform the data in `df2` with the scaler\n",
        "scaled_df = scaler.transform(df4)\n",
        "scaled_df.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVzP3hFIf7C9"
      },
      "source": [
        "train_data, test_data = df4.randomSplit(train_test, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qs8184Lf8rU"
      },
      "source": [
        "model3 = lr.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT6VXGzdf-A0"
      },
      "source": [
        "lrPred3 = model3.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yStVfGTf_ru"
      },
      "source": [
        "mse = eval.evaluate(lrPred3, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}